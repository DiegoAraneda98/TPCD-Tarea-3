{"cells":[{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["# **Modelo de Clasificación  K-Vecinos y Regresión logística**\n","\n","Para el problema de clasificar la calidad de una banana (good o bad) basandonos en distintas características, tanto la regresión logística como el modelo k-vecinos más cercanos (k-NN) son opciones viables. Por lo tanto abordaremos ambos modelos para comparar cual es el mejor. Esto ya que si deseamos interpretar cómo cada característica afecta la probabilidad de calidad good o bad, y si las relaciones pueden logísticas, la regresión logística podría ser la mejor opción. En cambio, al preferir otro enfoque más flexible, el cual pueda manejar relaciones no lineales y no necesitas una interpretación detallada de cada característica, el modelo k-NN podría ser más adecuado. Es por estas razones que se aplicaran ambos modelos.\n","\n","Actualmente, se tiene clasificado la calidad de las bananas en dos grupos. Si la utilización de los datos relacionados a distintas caracteristicas de la banana puede servirnos para predecir a que grupo al cual pertenecen, el hecho de predecir la calidad de una banana ayudaria con la reducción del desperdicio de alimentos, ya que no solo permitiria optimizar el inventario, si no tambien el consumo, asegurando que las bananas se vendan y se consuman en su punto óptimo de madurez, lo que reduce significativamente el desperdicio de alimentos, esta tarea por lo tanto sería un problema de clasificación. Es decir, dado el conjunto de datos, se necesita construir un modelo para predecir la calidad de una nueva banana.\n","\n","Para este caso, se usarán caracteristicas de la banana, las cuales son: Tamaño (Size), Peso (Weight), Dulzura (Sweetness), Suavidad (Softness), Tiempo de cosecha (HarvestTime), Madurez (Ripeness), Acidez (Acidity).\n","\n","El campo de destino, llamado `Quality`, tiene dos valores posibles que corresponden a los dos estados en los que puede estar la banana, de la siguiente manera:\n","\n","0. Bad\n","1. Good\n","\n","\n","Como se menciono anteriormente, se trabajará un conjunto de datos relacionado con la calidad de las bananas. Luego, se dividirán los datos en conjuntos de entrenamiento y prueba, se creará un modelo usando el conjunto de entrenamiento, se evaluará su modelo usando el conjunto de prueba y finalmente se usará el modelo para predecir el valor desconocido."]},{"cell_type":"markdown","metadata":{},"source":["## Tabla de Contenidos\n","\n","1. [Importar y Preparar los Datos de Análisis](#2)\n","2. [Pre-procesamiento de los datos](#3)\n","3. [Configuración del modelo K-vecinos](#4)\n","4. [Regresión logística](#5)\n","5. [Configuración del Modelo de Regresión logística](#6)\n","6. [Conclusiones de los modelos de clasificación](#7)\n"]},{"cell_type":"markdown","metadata":{},"source":["lusiones de los modelos de clasificación](#7)\n"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Importar y Preparar los Datos de Análisis <a id=\"2\"></a>"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["## Carga y Preparación de Datos"]},{"cell_type":"markdown","metadata":{},"source":["Instalar e importar Bibliotecas:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Instalar bibliotecas específicas para trabajar \n","!pip install numpy\n","!pip install pandas\n","!pip install matplotlib\n","!pip install scipy\n","!pip install scikit-learn\n","!pip3 install seaborn"]},{"cell_type":"markdown","metadata":{},"source":["Importar los paquetes de procesamiento y visualización de datos **pandas**, **numpy**, **matplotlib**, **sklearn** y **scipy**. No olvidar de poner `% matplotlib inline` para que las gráficas puedan aparecer en *Jupyter Notebook*."]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn import preprocessing\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from scipy import stats\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## Leer el Conjunto de Datos"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["Cargar los datos y guardarlos en el dataframe `df`:"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["# ruta de datos y leer los datos para guardarlos en df\n","\n","path='datos/banana_quality.csv'\n","df = pd.read_csv(path)"]},{"cell_type":"markdown","metadata":{},"source":["Al visualizar variables individuales, es importante saber el tipo de variable que se está tratando, para aquello se usara `df.dtypes` para ver de que tipo son cada variable:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# mostrar los 5 primeros registros de conjunto de datos\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Inicialmente el DataFrame contiene una columna llamada **Quality**, la cuál contiene dos valores tipo object, Good y Bad, que fueron cambiados a 1 y 0 respectivamente, para poder estudiar la correlación entre las variables "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['Quality'] = df['Quality'].replace({'Good': 1, 'Bad': 0})"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["# mostrar los 5 primeros registros de conjunto de datos luego del cambio del campo Quality\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Pre-procesamiento de los Datos<a id=\"3\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["\n","Antes de iniciar con la configuración del modelo, se realizará un preprocesamiento de los datos. Este incluirá un análisis de correlación para seleccionar las características más relevantes que contribuirán al desempeño del modelo. En particular, se evaluará la correlación de Pearson para identificar las variables que tienen una relación significativa con la variable objetivo. Las características que demuestren una correlación alta se conservarán, optimizando así el conjunto de datos para el entrenamiento del modelo."]},{"cell_type":"markdown","metadata":{},"source":["Primero se va a realizar un rápido análisis y visualización de los Datos. Se utilizara el metodo `df.value_counts()`, para observar cuantas bananas hay en cada clase en el conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['Quality'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["Como se puede observar, hay 4006 Bananas de calidad Buena (Good) y 3994 Bananas de calidad Mala (Bad)"]},{"cell_type":"markdown","metadata":{},"source":["## Correlación y Correlación de Pearson \n","A continuación se analizará la correlación y la correlación de Pearson, las cuales son fundamentales para entender las relaciones entre las variables. La correlación nos ayudará, en términos generales, a identificar si dos variables tienen alguna relación. Luego, al aplicar y observar la correlación de Pearson específicamente, mediremos la relación lineal entre las variables continuas del DataFrame df, cuantificándola con un coeficiente que varía entre -1 y 1. La correlación de Pearson nos servirá de ayuda para cuantificar qué tan bien una variable puede predecir a la otra."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.corr(numeric_only=True)"]},{"cell_type":"markdown","metadata":{},"source":["Para evaluar la significancia estadística, que es una medida de la fiabilidad en los resultados de un análisis y que permite tomar decisiones con mayor confianza, utilizaremos la correlación de Pearson para cada característica de la banana en relación con su calidad. Esto nos ayudará a determinar qué tan bien cada característica puede predecir la calidad de la banana."]},{"cell_type":"markdown","metadata":{},"source":["##  Peso versus Calidad"]},{"cell_type":"markdown","metadata":{},"source":["Calcular el coeficiente de la **Correlación de Pearson** y el **valor P** de `Weight` y `Quality`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coeficiente_pearson, valor_p = stats.pearsonr(df['Weight'], df['Quality'])\n","print(\"El coeficiente de la Correlación de Pearson es\", coeficiente_pearson, \" con un valor de P =\", valor_p)"]},{"cell_type":"markdown","metadata":{},"source":["##  Tamaño versus Calidad"]},{"cell_type":"markdown","metadata":{},"source":["Calcular el coeficiente de la **Correlación de Pearson** y el **valor P** de `Size` y `Quality`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coeficiente_pearson, valor_p = stats.pearsonr(df['Size'], df['Quality'])\n","print(\"El coeficiente de la Correlación de Pearson es\", coeficiente_pearson, \" con un valor de P =\", valor_p)"]},{"cell_type":"markdown","metadata":{},"source":["##  Dulzura versus Calidad"]},{"cell_type":"markdown","metadata":{},"source":["Calcular el coeficiente de la **Correlación de Pearson** y el **valor P** de `Sweetness` y `Quality`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coeficiente_pearson, valor_p = stats.pearsonr(df['Sweetness'], df['Quality'])\n","print(\"El coeficiente de la Correlación de Pearson es\", coeficiente_pearson, \" con un valor de P =\", valor_p)"]},{"cell_type":"markdown","metadata":{},"source":["##  Blandura versus Calidad"]},{"cell_type":"markdown","metadata":{},"source":["Calcular el coeficiente de la **Correlación de Pearson** y el **valor P** de `Softness` y `Quality`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coeficiente_pearson, valor_p = stats.pearsonr(df['Softness'], df['Quality'])\n","print(\"El coeficiente de la Correlación de Pearson es\", coeficiente_pearson, \" con un valor de P =\", valor_p)"]},{"cell_type":"markdown","metadata":{},"source":["##  Tiempo cosecha versus Calidad"]},{"cell_type":"markdown","metadata":{},"source":["Calcular el coeficiente de la **Correlación de Pearson** y el **valor P** de `HarvestTime` y `Quality`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coeficiente_pearson, valor_p = stats.pearsonr(df['HarvestTime'], df['Quality'])\n","print(\"El coeficiente de la Correlación de Pearson es\", coeficiente_pearson, \" con un valor de P =\", valor_p)"]},{"cell_type":"markdown","metadata":{},"source":["##  Madurez versus Calidad"]},{"cell_type":"markdown","metadata":{},"source":["Calcular el coeficiente de la **Correlación de Pearson** y el **valor P** de `Ripeness` y `Quality`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coeficiente_pearson, valor_p = stats.pearsonr(df['Ripeness'], df['Quality'])\n","print(\"El coeficiente de la Correlación de Pearson es\", coeficiente_pearson, \" con un valor de P =\", valor_p)"]},{"cell_type":"markdown","metadata":{},"source":["##  Acidez versus Calidad"]},{"cell_type":"markdown","metadata":{},"source":["Calcular el coeficiente de la **Correlación de Pearson** y el **valor P** de `Acidity` y `Quality`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["coeficiente_pearson, valor_p = stats.pearsonr(df['Acidity'], df['Quality'])\n","print(\"El coeficiente de la Correlación de Pearson es\", coeficiente_pearson, \" con un valor de P =\", valor_p)"]},{"cell_type":"markdown","metadata":{},"source":["En base a los datos recopilados de correlación y de los respectivos **valores de P**, las dos características que se descartaran con el objetivo simplificar el modelo sin perder información relevante sobre la calidad de las bananas, son:\n","\n","- Softness: Tiene un coeficiente de correlación casi nulo (-0.0016) y un valor p muy alto (0.88), indicando que no hay una relación significativa con la calidad de la banana.\n","\n","- Acidity: De una manera similar, tiene un coeficiente de correlación casi nulo (-0.00089) y un valor p muy alto (0.93), indicando que no hay una relación significativa con la calidad de la banana.\n"]},{"cell_type":"markdown","metadata":{},"source":["Un paso importante es definir las variable **X** e **y** y que atributos o características la van a componer. Para ello se usaran las caracteristicas que no fueron descartadas anteriormente."]},{"cell_type":"markdown","metadata":{},"source":["Para crear la variable `X` pasaremos el datafrma de *Pandas* a un arreglo *Numpy* para usar la biblioteca *scikit-learn*. Eliminando la variable de respuesta o dependiente."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df[['Size', 'Weight', 'Sweetness', 'HarvestTime', 'Ripeness']].values  #.astype(float)\n","X[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["Siguiendo el mismo procedimiento para crear la variable `y2` con el atributo o variable dependiente `Quality` que contiene el valor de las etiquetas."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = df['Quality'].values\n","y[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["El último paso del pre-procesamiento de los datos de entrada consiste **Normalizar los Datos**, esto se hara para el algortimo *K-Vecino más Cercano*, que se basa en la distancia de los casos de clasificación."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = preprocessing.StandardScaler().fit_transform(X)\n","X[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Configuración modelo K-vecinos <a id=\"4\"></a>\n","\n","Antes de comenzar con el modelado, hay que separar los datos en conjuntos de entrenamiento y prueba, esta parte es importante para mejorar la precisión fuera de la muestra del modelo. La precisión fuera de la muestra se refiere a qué tan bien el modelo predice datos nuevos que no ha visto antes. Es por esto que si entrenamos y probamos el modelo con el mismo conjunto de datos, puede aprender demasiado de los datos, un problema conocido como sobreajuste. Entonces al dividir los datos en dos conjuntos permitiria que al momento de entrenar el modelo en un conjunto y probarlo en otro que no ha visto, nos proporcione una evaluación más realista y precisa de su rendimiento en datos desconocidos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_entrena, X_prueba, y_entrena, y_prueba = train_test_split( X, y, test_size=0.2, random_state=4)\n","print ('Conjunto de Entrenamiento set:', X_entrena.shape,  y_entrena.shape)\n","print ('Conjunto de Prueba:', X_prueba.shape,  y_prueba.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Modelado"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Importar y cargar el módulo `neighbors` que habilita el clasificador que implementa el modelo del K-Vecinos más Cercano.\n","from sklearn.neighbors import KNeighborsClassifier"]},{"cell_type":"markdown","metadata":{},"source":["A continuación se crea una instancia del modelo para luego entrenar el modelo con los conjuntos de datos de entrenamiento. Inicialmente se procedio al entrenamiento del algoritmo con k=7, pero luego de ver el k mas optimo se dejo en k =14."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["k = 14\n","# Crear y entrenar el modelo y pronosticar  \n","vecino = KNeighborsClassifier(n_neighbors = k)\n","vecino.fit(X_entrena,y_entrena)\n","vecino"]},{"cell_type":"markdown","metadata":{},"source":["## Pronóstico"]},{"cell_type":"markdown","metadata":{},"source":["Ahora ya creada la instancia,  se puede usar el modelo para predecir el conjunto de prueba."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_hat = vecino.predict(X_prueba)\n","y_hat[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluación"]},{"cell_type":"markdown","metadata":{},"source":["En la clasificación multi-etiqueta, `accuracy_score` es una función que calcula la precisión del subconjunto. Esencialmente, esta funcion calcula qué tan cerca coinciden las etiquetas reales y las etiquetas predichas en el conjunto de prueba."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Precisión del conjunto de entrenamiento: \", metrics.accuracy_score(y_entrena, vecino.predict(X_entrena)))\n","print(\"Precisión del conjunto de prueba: \", metrics.accuracy_score(y_prueba, y_hat))"]},{"cell_type":"markdown","metadata":{},"source":["## Refinamiento"]},{"cell_type":"markdown","metadata":{},"source":["En KNN, \\( K \\) es el número de vecinos más cercanos que se considera para hacer una predicción. Elegir el valor correcto de \\( K \\) es crucial para obtener el mejor rendimiento de nuestro modelo. Un \\( K \\) demasiado bajo puede hacer que el modelo sea demasiado sensible al ruido en los datos (sobreajuste), mientras que un \\( K \\) demasiado alto puede hacer que el modelo sea demasiado general y no capture bien las relaciones en los datos (subajuste). Para encontrar el \\( K \\) óptimo, se irán probando varios valores reservando una parte de los datos para pruebas, empezando con un \\( K = 1 \\), entrenando el modelo y midiendo la precisión usando los datos de prueba. Luego, se aumentará \\( K \\) y se repetirá el proceso."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Ks = 20\n","prec_promedio = np.zeros((Ks-1))\n","prec_estandar = np.zeros((Ks-1))\n","matriz_confusion = [];\n","for n in range(1,Ks):\n","    # Entrena el modelo y pronostica  \n","    vecino_n = KNeighborsClassifier(n_neighbors = n).fit(X_entrena,y_entrena)\n","    y_hat=vecino_n.predict(X_prueba)\n","    prec_promedio[n-1] = metrics.accuracy_score(y_prueba, y_hat)\n","    prec_estandar[n-1] = np.std(y_hat==y_prueba)/np.sqrt(y_hat.shape[0])\n","\n","print('Precisión promedio: ',prec_promedio)\n","print('Precisión desviación estándar: ',prec_estandar)"]},{"cell_type":"markdown","metadata":{},"source":["Grafico de la precisión del modelo para un número $k$ diferente de vecinos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(range(1,Ks),prec_promedio,'g')\n","plt.fill_between(range(1,Ks),prec_promedio - 1 * prec_estandar,prec_promedio + 1 * prec_estandar, alpha=0.10)\n","plt.legend(('Precisión ', '+/- 3xstd'))\n","plt.ylabel('Precisión ')\n","plt.xlabel('Número de vecinos (K)')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print( \"La mejor precisión se obtuvo con\", prec_promedio.max(), \"con k=\", prec_promedio.argmax()+1) "]},{"cell_type":"markdown","metadata":{},"source":["Ahora observaremos, como es la matriz de confusión de este modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Esta función imprime y grafica una matriz de confusión.\n","# Se puede aplicar una normalización configurando el parámetro `normalize=True`.\n","\n","import itertools\n","\n","def grafica_matriz_confusion(matr_conf, clases,\n","                          normalizar=False,\n","                          titulo='Matriz de Confusión',\n","                          cmap=plt.cm.Blues):\n","\n","    if normalizar:\n","        matr_conf = matr_conf.astype('float') / matr_conf.sum(axis=1)[:, np.newaxis]\n","        print(\"Matriz de Confusión Normalizada.\")\n","    else:\n","        print('Matriz de Confusión matrix sin normalización')\n","\n","    print(matr_conf)\n","\n","    plt.imshow(matr_conf, interpolation='nearest', cmap=cmap)\n","    plt.title(titulo)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(clases))\n","    plt.xticks(tick_marks, clases, rotation=45)\n","    plt.yticks(tick_marks, clases)\n","\n","    formato = '.2f' if normalizar else 'd'\n","    umbral = matr_conf.max() / 2.\n","    for i, j in itertools.product(range(matr_conf.shape[0]), range(matr_conf.shape[1])):\n","        plt.text(j, i, format(matr_conf[i, j], formato),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if matr_conf[i, j] > umbral else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('Etiqueta valores Verdaderos')\n","    plt.xlabel('Etiqueta valores Pronosticados')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","matriz_confusion = metrics.confusion_matrix(y_prueba, y_hat, labels=[1,0])\n","np.set_printoptions(precision=2)\n","\n","# Grafica matriz de confusión no normalizada\n","plt.figure()\n","grafica_matriz_confusion(matriz_confusion, clases=['Quality=1','Quality=0'],normalizar= False,  titulo='Matriz de Confusión')"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Regresión logística <a id=\"5\"></a>\n"]},{"cell_type":"markdown","metadata":{},"source":["Cargar los datos y guardarlos en el dataframe `df4`:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["path4='datos/banana_quality.csv'\n","df4 = pd.read_csv(path4)\n","df4.head()"]},{"cell_type":"markdown","metadata":{},"source":["Tamaño y forma del conjunto de datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Tamaño: ', df4.size)\n","print('Forma: ', df4.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Al igual que se hizo para el modelo de k-vecinos, se reemplazará la columna `Quality` por 0 y 1, ya que el tipo de dato objetivo debe ser un número entero, lo cual es un requisito del módulo a utilizar de `scikit-learn`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df4['Quality'] = df4['Quality'].replace({'Good': 1, 'Bad': 0})"]},{"cell_type":"markdown","metadata":{},"source":["Definir **X4** e **y4** a partir del conjunto de datos seleccionado en el modelo pasado, es decir dejando solo las columnas que no fueron descartadas."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X4 = np.asarray(df4[['Size', 'Weight', 'Sweetness', 'HarvestTime', 'Ripeness']])\n","X4[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y4 = np.asarray(df4['Quality'])\n","y4 [0:5]"]},{"cell_type":"markdown","metadata":{},"source":["Además, se normalizara el conjunto de datos asociado a la variable **X4**:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X4 = preprocessing.StandardScaler().fit_transform(X4)\n","X4[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["# 4.Configuración del Modelo de Regresión logística <a id=\"6\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, se dividira el conjunto de datos en el conjunto de entrenamiento y el conjunto de prueba\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X4_entrena, X4_prueba, y4_entrena, y4_prueba = train_test_split(X4, y4, test_size=0.2, random_state=4)\n","print ('Conjunto de Entrenamiento set:', X4_entrena.shape,  y4_entrena.shape)\n","print ('Conjunto de Prueba:', X4_prueba.shape,  y4_prueba.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Modelado Regresión logística"]},{"cell_type":"markdown","metadata":{},"source":["El siguiente paso es utilizar el módulo `LogisticRegression` de la biblioteca `Scikit-learn` para construir nuestro modelo. La regresión logística es un método que se usa para predecir resultados binarios, como sí o no, o como en nuestro caso Good o Bad y puede ajustarse para evitar que nuestro modelo se sobreajuste a los datos de entrenamiento. El parámetro `C` en la regresión logística controla la fuerza de esta regularización, valores de  `C` más pequeños significan una regularización más fuerte, lo que ayudaria a evitar que el modelo se ajuste demasiado a los detalles específicos de los datos de entrenamiento. Una vez importado el módulo `LogisticRegression`, ajustaremos nuestro modelo usando el conjunto de entrenamiento para que aprenda a predecir correctamente los resultados deseados."]},{"cell_type":"markdown","metadata":{},"source":["- Para es caso se usara solve = `liblinear`, ya que este solucionador está optimizado para problemas de clasificación binaria y es eficiente en términos de memoria. Ademas al ser problema estándar de clasificación binaria y no tener restricciones específicas adicionales es util utilizarlo, en vez de lbfgs."]},{"cell_type":"markdown","metadata":{},"source":["Antes de realizar la construcción del modelo, utilizaremos validación cruzada para encontrar el mejor valor para C. Así podremos evaluar el rendimiento del modelo con diferentes valores de C y seleccionar el que proporciona los mejores resultados.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np\n","\n","# Definir diferentes valores de C a probar\n","C_values = [0.01, 0.1, 1, 10, 100]\n","scores = {}\n","\n","for C in C_values:\n","    model = LogisticRegression(C=C, solver='liblinear') \n","    cv_scores = cross_val_score(model, X4_entrena,y4_entrena, cv=5, scoring='accuracy')\n","    scores[C] = np.mean(cv_scores)\n","\n","\n","for C, score in scores.items():\n","    print(f\"Precisión promedio con C={C}: {score}\")\n","\n","# Determinar el mejor valor de C\n","best_C = max(scores, key=scores.get)\n","print(f\"Mejor valor de C: {best_C}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","\n","regr_logi = LogisticRegression(C=0.01, solver='liblinear').fit(X4_entrena,y4_entrena)\n","regr_logi"]},{"cell_type":"markdown","metadata":{},"source":["## Pronóstico Regresión logística"]},{"cell_type":"markdown","metadata":{},"source":["Una vez entrenado el modelo se puede realizar el pronóstico o prediccion con el conjunto de datos de prueba."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y4_hat = regr_logi.predict(X4_prueba)\n","y4_hat"]},{"cell_type":"markdown","metadata":{},"source":["La función `predict_proba` devuelve estimaciones para las clases que hay, ordenadas por la etiqueta de las clases. Así, la primera columna es la probabilidad de la clase 0 y la segunda columna es la probabilidad de la clase 1."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y4_hat_prob = regr_logi.predict_proba(X4_prueba)\n","y4_hat_prob"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluación Regresión logística"]},{"cell_type":"markdown","metadata":{},"source":["**Índice de Jaccard**\n","\n","Se utilizará el **índice jaccard** para evaluar la precisión. Si todo el conjunto de etiquetas pronosticadas para una muestra coincide estrictamente con el verdadero conjunto de etiquetas, entonces la precisión del subconjunto es $1,0$; de lo contrario es $0,0$."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics.jaccard_score(y4_prueba, y4_hat)"]},{"cell_type":"markdown","metadata":{},"source":["\n","El valor de 0.7861271676300579 sugiere que las etiquetas predichas tienen una similitud del 78.61% con las etiquetas reales, lo cual nos podria indicar que es una medida positiva de la precisión del modelo en la clasificación multiclase."]},{"cell_type":"markdown","metadata":{},"source":["**Matiz de Confusión**\n","\n","Otra forma de observar la precisión del modelo, es mediante la matriz de confusión. Con la matriz podremos ver en forma de tabla cuántas predicciones de cada clase son correctas o incorrectas. Cada columna representa el número de predicciones para una clase, y cada fila muestra cuántas instancias reales pertenecen a esa clase. Esto permite analizar cómo el modelo clasifica cada clase y ayuda a identificar los tipos de errores y aciertos que comete el modelo.\n","\n","A continuación se define una función para graficar una matriz de confusión."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Esta función imprime y grafica una matriz de confusión.\n","# Se puede aplicar una normalización configurando el parámetro `normalize=True`.\n","\n","import itertools\n","\n","def grafica_matriz_confusion(matr_conf, clases,\n","                          normalizar=False,\n","                          titulo='Matriz de Confusión',\n","                          cmap=plt.cm.Blues):\n","\n","    if normalizar:\n","        matr_conf = matr_conf.astype('float') / matr_conf.sum(axis=1)[:, np.newaxis]\n","        print(\"Matriz de Confusión Normalizada.\")\n","    else:\n","        print('Matriz de Confusión matrix sin normalización')\n","\n","    print(matr_conf)\n","\n","    plt.imshow(matr_conf, interpolation='nearest', cmap=cmap)\n","    plt.title(titulo)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(clases))\n","    plt.xticks(tick_marks, clases, rotation=45)\n","    plt.yticks(tick_marks, clases)\n","\n","    formato = '.2f' if normalizar else 'd'\n","    umbral = matr_conf.max() / 2.\n","    for i, j in itertools.product(range(matr_conf.shape[0]), range(matr_conf.shape[1])):\n","        plt.text(j, i, format(matr_conf[i, j], formato),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if matr_conf[i, j] > umbral else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('Etiqueta valores Verdaderos')\n","    plt.xlabel('Etiqueta valores Pronosticados')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calcular matriz de confusión\n","\n","matriz_confusion = metrics.confusion_matrix(y4_prueba, y4_hat, labels=[1,0])\n","np.set_printoptions(precision=2)\n","\n","# Grafica matriz de confusión no normalizada\n","plt.figure()\n","grafica_matriz_confusion(matriz_confusion, clases=['Quality=1','Quality=0'],normalizar= False,  titulo='Matriz de Confusión')"]},{"cell_type":"markdown","metadata":{},"source":["**Análisis de la primera fila**: La primera fila es para las bananas cuyo valor real de calidad en el conjunto de prueba es 1 (es decir, La calidad de la banana es Buena). Como se puede calcular, de 1600 bananas, 777 de ellos tienen el valor de abandono en 1. Y de estos 777, el clasificador predijo correctamente 680 de ellas como 1 y predijo erróneamente 97 de ellas como 0.\n","\n","Esto significa que, para 680 bananas, el valor real de su calidad fue 1 en el conjunto de prueba, y el clasificador también los predijo correctamente como 1. Sin embargo, mientras que la etiqueta real de 97 bananas fue 1, el clasificador los predijo como 0, lo cual no es correcto. Esto se puede considerar como un error del modelo para la primera fila.\n","\n","**Análisis de la segunda fila**: Hay 823 bananas cuyo valor de calidad era 0 (es decir, malas). El clasificador predijo correctamente 735 de ellos como 0 y 88 de ellos incorrectamente como 1. Por lo tanto, se observa un mayor numero de aciertos , aunque la cantidad de error igual es alta.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print (metrics.classification_report(y4_prueba, y4_hat))"]},{"cell_type":"markdown","metadata":{},"source":[" **Interpretación General**\n","- La **exactitud** del 88% indica que el modelo es capaz de clasificar correctamente una alta proporción de las muestras totales.\n","- Los **F1-scores** cercanos al 0.88 para ambas clases muestran que el modelo tiene un buen equilibrio entre precisión y recall.\n","En resumen, tanto la exactitud como el F1-score sugieren que tu modelo tiene un rendimiento sólido y equilibrado, siendo capaz de manejar bien las dos clases presentes."]},{"cell_type":"markdown","metadata":{},"source":["**Pérdida Logística**\n","\n","La pérdida logística o **log-loss** es una métrica que indica qué tan cerca está la probabilidad de predicción del valor real/verdadero correspondiente (0 o 1 en caso de clasificación binaria). Cuanto más diverja la probabilidad predicha del valor real, mayor será el valor de pérdida logarítmica.\n","\n","Ahora, se probará realizar una evaluación  **log-loss** para el modelo. En la regresión logística, el resultado puede ser que la probabilidad de abandono de clientes sea sí (o igual a 1). Esta probabilidad es un valor entre 0 y 1. Por lo tanto, **log-loss** mide el rendimiento de un clasificador donde la salida prevista es un valor de probabilidad entre 0 y 1.\n","\n","Este indicador se utiliza, principalmente para comparar modelos. El modelo que tenga el menor valor de **log-loss** será el mejor evaluado."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print (\"Pérdila logística: %.4f\" % metrics.log_loss(y4_prueba, y4_hat_prob))"]},{"cell_type":"markdown","metadata":{},"source":["Esto sugiere que el modelo podría estar generalizando mejor o ajustándose más cerca de los datos reales."]},{"cell_type":"markdown","metadata":{},"source":["# Conclusiones de los modelos de clasificación <a id=\"7\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["En base a la comparación entre distintos puntos de ambos modelos, tendremos lo siguiente:\n","\n","**Precisión Global:**\n","- El modelo K-Vecinos tiene una precisión global ligeramente mejor en el conjunto de prueba (0.934375) en comparación con la precisión global del modelo de regresión logística (0.88).\n","\n","**Matriz de Confusión:**\n","- Ambos modelos muestran una buena distribución de verdaderos positivos y verdaderos negativos, pero el modelo K-Vecinos tiene un menor número de falsos positivos (50 vs 97) y falsos negativos (58 vs 88) en comparación con el modelo de regresión logística.\n","\n","**Informe de Clasificación:**\n","- Ambos modelos tienen métricas de precisión, recall y F1-score muy similares en ambas clases, lo que sugiere que su rendimiento es comparable en términos de estas métricas.\n","\n","**Pérdida Logística y Jaccard:**\n","- La pérdida logística del segundo modelo es 0.3027, lo cual es un buen valor indicando que el modelo está bien ajustado. El índice de Jaccard de 0.7861 sugiere una buena similitud entre las predicciones y las etiquetas verdaderas.\n","\n","**Conclusión:**\n","Basándonos en la precisión global, la matriz de confusión y el informe de clasificación, el modelo de K-Vecinos con k=14 parece tener un rendimiento ligeramente mejor que el modelo de regresión logística. Esto se refleja principalmente en la menor cantidad de falsos positivos y falsos negativos que obtuvieron ambos modelos."]},{"cell_type":"markdown","metadata":{},"source":["# **Modelo de**\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}},"widgets":{"state":{},"version":"1.1.2"}},"nbformat":4,"nbformat_minor":2}
